<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-12-11 Wed 17:51 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Sam Partee" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgbe2c879">1. NeurIPS 2019</a>
<ul>
<li><a href="#org76da0ea">1.1. Sunday</a>
<ul>
<li><a href="#org3e79b3e">1.1.1. Habana Labs</a></li>
<li><a href="#org5424145">1.1.2. Facebook Hardware</a></li>
<li><a href="#org221e977">1.1.3. ML in Finance</a></li>
</ul>
</li>
<li><a href="#orgf5286cd">1.2. Monday (tutorials)</a>
<ul>
<li><a href="#org9e03819">1.2.1. Deep Learning with Bayesian Principles</a></li>
<li><a href="#org327446f">1.2.2. Efficent Processing of Deep Neural Network</a></li>
<li><a href="#org469ce72">1.2.3. Reinforcement Learning: Past, Present, and future Prospectives</a></li>
</ul>
</li>
<li><a href="#orgd5f905b">1.3. Tuesday</a>
<ul>
<li><a href="#org9ec7475">1.3.1. Uniform Convergence may be unable to Explain generalization in Deep Learning</a></li>
<li><a href="#org81ed718">1.3.2. Logarithmic Regret for Online Control</a></li>
<li><a href="#org079955c">1.3.3. Legendre Memory Units: Continuous Time Representation in RNNs</a></li>
<li><a href="#org8d7bfcf">1.3.4. Point Voxel CNN for Efficent 3D Deep Learning</a></li>
<li><a href="#orgd6627f7">1.3.5. Neural Networks with Cheap Differential Operators</a></li>
<li><a href="#org84a5792">1.3.6. Sequential Neural Processes</a></li>
<li><a href="#orgadcd1f7">1.3.7. Conditiional Independance Testing Using GANs</a></li>
<li><a href="#orga0a5055">1.3.8. Machine Learning Meets Single-Cell Biology: Insights and Challenges</a></li>
<li><a href="#org362db81">1.3.9. Causal Confusion in Imitation Learning</a></li>
<li><a href="#orgc2d792f">1.3.10. Generative Modeling by Estimating Gradients of the Data Distribution</a></li>
<li><a href="#orgc590abf">1.3.11. Reducing the Varience in Online Optimization by Transporting Past Gradients</a></li>
<li><a href="#org5d720b3">1.3.12. SySCD: A System-Aware Parallel Coordinate Descent Algorithm</a></li>
<li><a href="#orgf48d7ad">1.3.13. Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies</a></li>
<li><a href="#org74bb975">1.3.14. Hindsight Credit Assignment</a></li>
<li><a href="#orga4dacec">1.3.15. Weight Agnostic Neural Networks</a></li>
</ul>
</li>
<li><a href="#org0230e86">1.4. Wednesday</a>
<ul>
<li><a href="#orgd1e8bd2">1.4.1. Fast and Accurate Least-Mean-Squares Solvers</a></li>
<li><a href="#org147df3c">1.4.2. Calibration tests in multi-class classification: A unifying framework</a></li>
<li><a href="#org9317b3b">1.4.3. Verified Uncertainty Calibration</a></li>
<li><a href="#org6f5570c">1.4.4. Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</a></li>
<li><a href="#org1632985">1.4.5. Principal Component Projection and Regression in Nearly Linear Time through Asymmetric SVRG</a></li>
<li><a href="#org862a155">1.4.6. PIDForest: Anomaly Detection via Partial Identification</a></li>
<li><a href="#orgf52eb61">1.4.7. Guided Similarity Seperation for Image Retrieval</a></li>
<li><a href="#orgf953e87">1.4.8. CNAPs: Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes</a></li>
<li><a href="#org734423a">1.4.9. Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation</a></li>
<li><a href="#org650b5f3">1.4.10. Efficient Meta Learning via Minibatch Proximal Update</a></li>
<li><a href="#orgf8d2b6e">1.4.11. Reconciling meta-learning and continual learning with online mixtures of tasks</a></li>
<li><a href="#org1861b5b">1.4.12. Beyond Online Balanced Descent: An Optimal Algorithmfor Smoothed Online Convex Optimization</a></li>
<li><a href="#org181aefb">1.4.13. Strategizing against No-regret Learners</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgbe2c879" class="outline-2">
<h2 id="orgbe2c879"><span class="section-number-2">1</span> NeurIPS 2019</h2>
<div class="outline-text-2" id="text-1">
<p>
This repository is a collection of the papers and my notes from attended talks
and other various parts of NeurIPS 2019. I created this repository mostly for my
own sake, but also because I found it painstaking to find the papers and slides
for the various talks I wanted to go to. Included also are my personal notes that
will be updated as the week goes on.
</p>
</div>

<div id="outline-container-org76da0ea" class="outline-3">
<h3 id="org76da0ea"><span class="section-number-3">1.1</span> Sunday</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org3e79b3e" class="outline-4">
<h4 id="org3e79b3e"><span class="section-number-4">1.1.1</span> Habana Labs</h4>
<div class="outline-text-4" id="text-1-1-1">
<ul class="org-ul">
<li><a href="./habana-labs.html">Notes</a></li>
<li>Talk was a brief showcase of the Habana Goya Inference Processor.
If youre not familiar with this type of processor, they allow you
to fine-tune the inference of your model by reducing the precision
of your model without accuracy lost. This sentence liberally taken
from the Nvidia website and summerizes the importance of reduced
precision:</li>
</ul>
<p class="verse">
Reduced precision inference significantly reduces application<br />
latency, which is a requirement for many real-time services,<br />
auto and embedded applications.<br />
</p>
</div>
</div>
<div id="outline-container-org5424145" class="outline-4">
<h4 id="org5424145"><span class="section-number-4">1.1.2</span> Facebook Hardware</h4>
<div class="outline-text-4" id="text-1-1-2">
<ul class="org-ul">
<li><a href="./facebook-hardware.html">Notes</a></li>
<li>Very interesting talk on the Open Accelerator Intrastructure. Couldn't
stay for the whole thing, but the jist of it is that the OAI stack brings
an open source software feel to hardware. The stack aims to reduce the
time to integration for AI systems. There is an impressive number of
companies behind it including Habana. I couldl't stay for whole talk, but
for more detail see link below.</li>
<li><a href="https://www.opencompute.org/blog/new-open-accelerator-infrastructure-oai-sub-project-to-launch-within-the-ocp-server-project">OAI</a></li>
</ul>
</div>
</div>
<div id="outline-container-org221e977" class="outline-4">
<h4 id="org221e977"><span class="section-number-4">1.1.3</span> ML in Finance</h4>
<div class="outline-text-4" id="text-1-1-3">
<ul class="org-ul">
<li><a href="./ML-in-finance.html">Notes</a></li>
<li>Personal Note: Two Sigma folks were very nice and approachable.</li>
<li>Attend the end of the J.P. Morgan talk and the Two Sigma talk in
this session. Both were very high level talks about ML in finance.
J.P. Morgan covered the basics of RL and their application to
financial data. Two Sigma's talk broke down different uses of ML
for finding opportunies within the market. They provided an
example of how break down an instagram photo into consumable
data for CNNs(object-recognition) and LSTMs(sentiment analysis).
The process of training forecasting models was also covered.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf5286cd" class="outline-3">
<h3 id="orgf5286cd"><span class="section-number-3">1.2</span> Monday (tutorials)</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org9e03819" class="outline-4">
<h4 id="org9e03819"><span class="section-number-4">1.2.1</span> Deep Learning with Bayesian Principles</h4>
<div class="outline-text-4" id="text-1-2-1">
<ul class="org-ul">
<li><a href="./DL-with-Bayesian-Principles.html">Notes</a></li>
<li>Author, Mohammad Emtiyaz Khan, focused on the benefits of combining Bayesian Learning
and Deep Learning approaches. He showed how to derive common DL optimizers like
Adam and RMSProp from Bayesian principles. Khan stressed the importance of such
Bayesian principles in lifelong learning. This talk was one of my favorites because
Khan did a great job of distilling the benefits of Bayesian Learning into well explained
equations.</li>
</ul>
</div>
</div>
<div id="outline-container-org327446f" class="outline-4">
<h4 id="org327446f"><span class="section-number-4">1.2.2</span> Efficent Processing of Deep Neural Network</h4>
<div class="outline-text-4" id="text-1-2-2">
<ul class="org-ul">
<li><a href="./nn-processing.html">Notes</a></li>
<li>Vivenne Sze discussed the various processing methods available and being researched
for AI computation. Specifically, Sze drilled home the impact of reads from DRAM in
training. This talk was quite dense and covered many aspects of AI processing from
chip specifics to co-design and Neural Architecture Search (NAS).</li>
</ul>
</div>
</div>
<div id="outline-container-org469ce72" class="outline-4">
<h4 id="org469ce72"><span class="section-number-4">1.2.3</span> Reinforcement Learning: Past, Present, and future Prospectives</h4>
<div class="outline-text-4" id="text-1-2-3">
<ul class="org-ul">
<li><a href="./RL-overview.html">Notes</a></li>
<li>Katja Hofmann, a part of Microsoft Research, talked about Reinforcement Learning (Rl) from
inception to standard practice. Hofmann outlined Deep Q-Learning and some improvements that
have been made to the method such as Boostrapped DQNs from Osband et al. (2018). She then
explained the Actor Critic model and shared a number of papers I am going to go read.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd5f905b" class="outline-3">
<h3 id="orgd5f905b"><span class="section-number-3">1.3</span> Tuesday</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org9ec7475" class="outline-4">
<h4 id="org9ec7475"><span class="section-number-4">1.3.1</span> Uniform Convergence may be unable to Explain generalization in Deep Learning</h4>
<div class="outline-text-4" id="text-1-3-1">
<ul class="org-ul">
<li><a href="https://arxiv.org/pdf/1902.04742.pdf">Paper</a></li>
</ul>
</div>
</div>
<div id="outline-container-org81ed718" class="outline-4">
<h4 id="org81ed718"><span class="section-number-4">1.3.2</span> Logarithmic Regret for Online Control</h4>
<div class="outline-text-4" id="text-1-3-2">
<ul class="org-ul">
<li><a href="https://i-am-karan-singh.github.io/docs/log-control/summary.pdf">Slides</a></li>
<li><a href="./log-regret-online-control.pdf">Paper</a></li>
</ul>
</div>
</div>
<div id="outline-container-org079955c" class="outline-4">
<h4 id="org079955c"><span class="section-number-4">1.3.3</span> Legendre Memory Units: Continuous Time Representation in RNNs</h4>
<div class="outline-text-4" id="text-1-3-3">
<ul class="org-ul">
<li><a href="https://docs.google.com/document/d/1uarYP9YqcKx2Qh7sHJJhrY87C-mVZbNTAVqRKVPDXmI/edit">Supplementary material</a></li>
<li><a href="https://github.com/abr/neurips2019">Code</a></li>
<li><a href="./legendre_memory_units.pdf">Paper</a></li>
<li>Great talk that showed a nice hybrid arch of LSTM and LMU units for DL</li>
</ul>
</div>
</div>
<div id="outline-container-org8d7bfcf" class="outline-4">
<h4 id="org8d7bfcf"><span class="section-number-4">1.3.4</span> Point Voxel CNN for Efficent 3D Deep Learning</h4>
<div class="outline-text-4" id="text-1-3-4">
<ul class="org-ul">
<li><a href="https://hanlab.mit.edu/projects/pvcnn/">Site</a></li>
<li><a href="./Point-Voxel-3D-DL.pdf">Paper</a></li>
<li>Won gold model in Lyft Challenge</li>
<li>Shows large improvement from Point NN</li>
</ul>
</div>
</div>
<div id="outline-container-orgd6627f7" class="outline-4">
<h4 id="orgd6627f7"><span class="section-number-4">1.3.5</span> Neural Networks with Cheap Differential Operators</h4>
</div>
<div id="outline-container-org84a5792" class="outline-4">
<h4 id="org84a5792"><span class="section-number-4">1.3.6</span> Sequential Neural Processes</h4>
</div>
<div id="outline-container-orgadcd1f7" class="outline-4">
<h4 id="orgadcd1f7"><span class="section-number-4">1.3.7</span> Conditiional Independance Testing Using GANs</h4>
<div class="outline-text-4" id="text-1-3-7">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballsa+b(10-10-05)-10-10-40-15681-conditional_ind.pdf">Slides</a></li>
<li><a href="./Conditional-I-testing-GANs.pdf">Paper</a></li>
<li>GANS in high dimensional spaces</li>
</ul>
</div>
</div>
<div id="outline-container-orga0a5055" class="outline-4">
<h4 id="orga0a5055"><span class="section-number-4">1.3.8</span> Machine Learning Meets Single-Cell Biology: Insights and Challenges</h4>
<div class="outline-text-4" id="text-1-3-8">
<ul class="org-ul">
<li>Speaker: <a href="https://neurips.cc/Conferences/2019/Schedule?showSpeaker=3840-15485">Dana Pe'er</a></li>
<li>Biology is becoming a data science</li>
<li>Humancellatlas.org</li>
<li>Mentioned the success of tSNE for biological data
<ul class="org-ul">
<li><a href="https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b">tSNE and PCA</a></li>
</ul></li>
<li>Was able to use DS methods to discover a new cell type that formed a checkpoint
in DNA structure. Cell was as rare as 7 in 10000.</li>
<li>Was able to map the spatio-temporal development of mammalian endoderm.
<ul class="org-ul">
<li>Setty et al (2019), Nature</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org362db81" class="outline-4">
<h4 id="org362db81"><span class="section-number-4">1.3.9</span> Causal Confusion in Imitation Learning</h4>
<div class="outline-text-4" id="text-1-3-9">
<ul class="org-ul">
<li><a href="https://sites.google.com/view/causal-confusion">Site</a></li>
<li><a href="./Causal-Confusion.pdf">Paper</a></li>
<li><a href="https://github.com/pimdh/causal-confusion">Code</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgc2d792f" class="outline-4">
<h4 id="orgc2d792f"><span class="section-number-4">1.3.10</span> Generative Modeling by Estimating Gradients of the Data Distribution</h4>
<div class="outline-text-4" id="text-1-3-10">
<ul class="org-ul">
<li><a href="./gen-model-estim-gradients.pdf">Paper</a></li>
<li>Stable training as opposed to GANs</li>
<li>Better or comparable sample quality to GANs</li>
<li>Inpainting example was quite cool</li>
</ul>
</div>
</div>
<div id="outline-container-orgc590abf" class="outline-4">
<h4 id="orgc590abf"><span class="section-number-4">1.3.11</span> Reducing the Varience in Online Optimization by Transporting Past Gradients</h4>
<div class="outline-text-4" id="text-1-3-11">
<ul class="org-ul">
<li><a href="./Implicit-Gradient-Transport.pdf">Paper</a></li>
<li><a href="http://seba1511.net/projects/igt/">Project Website</a></li>
<li><a href="https://github.com/seba-1511/igt.pth">PyTorch Implementation</a></li>
</ul>
</div>
</div>
<div id="outline-container-org5d720b3" class="outline-4">
<h4 id="org5d720b3"><span class="section-number-4">1.3.12</span> SySCD: A System-Aware Parallel Coordinate Descent Algorithm</h4>
<div class="outline-text-4" id="text-1-3-12">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westexhibitionhallb(10-16-10)-10-17-05-15802-syscd_a_system.pdf">Slides</a></li>
<li><a href="https://www.zurich.ibm.com/snapml/neurips19/SySCD-poster-neurips19.pdf">Poster</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf48d7ad" class="outline-4">
<h4 id="orgf48d7ad"><span class="section-number-4">1.3.13</span> Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies</h4>
<div class="outline-text-4" id="text-1-3-13">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballsa+b(10-16-10)-10-17-15-15692-tight_regret_bo.pdf">Slides</a></li>
</ul>
</div>
</div>
<div id="outline-container-org74bb975" class="outline-4">
<h4 id="org74bb975"><span class="section-number-4">1.3.14</span> Hindsight Credit Assignment</h4>
<div class="outline-text-4" id="text-1-3-14">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=2EnckznIV2o&amp;feature=youtu.be">Video</a></li>
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballa+b(10-16-10)-10-17-20-15693-hindsight_credi.pdf">Slides</a></li>
</ul>
</div>
</div>
<div id="outline-container-orga4dacec" class="outline-4">
<h4 id="orga4dacec"><span class="section-number-4">1.3.15</span> Weight Agnostic Neural Networks</h4>
<div class="outline-text-4" id="text-1-3-15">
<ul class="org-ul">
<li><a href="./weight-agnostic-nn.pdf">Paper</a></li>
<li><a href="https://weightagnostic.github.io/slides/wann_slides.pdf">Slides</a></li>
<li><a href="https://weightagnostic.github.io/">Site</a></li>
<li>Questions the importance of architechture in the learning process. Makes the
comparison to Precocial species who have certain abilities provided at birth.</li>
<li>Shows that a neural architechture search can perform on multiple reinforcement
learning and supervised learning tasks.</li>
<li>Based on NEAT</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0230e86" class="outline-3">
<h3 id="org0230e86"><span class="section-number-3">1.4</span> Wednesday</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-orgd1e8bd2" class="outline-4">
<h4 id="orgd1e8bd2"><span class="section-number-4">1.4.1</span> Fast and Accurate Least-Mean-Squares Solvers</h4>
<div class="outline-text-4" id="text-1-4-1">
<ul class="org-ul">
<li><a href="./LMS.pdf">Paper</a></li>
<li>Novel method to compute caratheodory set</li>
<li>Mentioned heavy dependance on the dimensionality being low for benefits to show.</li>
</ul>
</div>
</div>
<div id="outline-container-org147df3c" class="outline-4">
<h4 id="org147df3c"><span class="section-number-4">1.4.2</span> Calibration tests in multi-class classification: A unifying framework</h4>
<div class="outline-text-4" id="text-1-4-2">
<ul class="org-ul">
<li><a href="./Calibration-error.pdf">Paper</a></li>
</ul>
</div>
</div>
<div id="outline-container-org9317b3b" class="outline-4">
<h4 id="org9317b3b"><span class="section-number-4">1.4.3</span> Verified Uncertainty Calibration</h4>
<div class="outline-text-4" id="text-1-4-3">
<ul class="org-ul">
<li><a href="https://github.com/AnanyaKumar/verified_calibration">code</a></li>
<li><a href="./uncertainty-calibration.pdf">Paper</a></li>
<li>Platt scaling, cannot estimate calibration</li>
<li>debiased estimator</li>
</ul>
</div>
</div>
<div id="outline-container-org6f5570c" class="outline-4">
<h4 id="org6f5570c"><span class="section-number-4">1.4.4</span> Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations</h4>
<div class="outline-text-4" id="text-1-4-4">
<ul class="org-ul">
<li><a href="https://vsitzmann.github.io/srns/video/">video</a></li>
<li><a href="https://vsitzmann.github.io/srns/slides.pdf">slides</a></li>
<li><a href="./Scene-Representation-Networks.pdf">paper</a></li>
<li><a href="https://vsitzmann.github.io/">Author Github.io</a></li>
</ul>
</div>
</div>
<div id="outline-container-org1632985" class="outline-4">
<h4 id="org1632985"><span class="section-number-4">1.4.5</span> Principal Component Projection and Regression in Nearly Linear Time through Asymmetric SVRG</h4>
<div class="outline-text-4" id="text-1-4-5">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballsa+b(11-10-05)-11-10-35-15700-principal_compo.pdf">Slides</a></li>
<li><a href="./PCA-SVRG.pdf">Paper</a></li>
<li>Combining PCA and linear projection and regression (PCP, PCR)</li>
</ul>
</div>
</div>
<div id="outline-container-org862a155" class="outline-4">
<h4 id="org862a155"><span class="section-number-4">1.4.6</span> PIDForest: Anomaly Detection via Partial Identification</h4>
<div class="outline-text-4" id="text-1-4-6">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballsa+b(11-10-05)-11-10-40-15701-pidforest_anom.pdf">slides</a></li>
<li><a href="./pidforest.pdf">paper</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf52eb61" class="outline-4">
<h4 id="orgf52eb61"><span class="section-number-4">1.4.7</span> Guided Similarity Seperation for Image Retrieval</h4>
<div class="outline-text-4" id="text-1-4-7">
<ul class="org-ul">
<li><a href="./Guided-Similarity-Seperation.pdf">paper</a></li>
<li>Graph convolutionall network that models the descriptor graph where
the descriptors are what are compared against for images to be retrieved.</li>
</ul>
</div>
</div>
<div id="outline-container-orgf953e87" class="outline-4">
<h4 id="orgf953e87"><span class="section-number-4">1.4.8</span> CNAPs: Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes</h4>
<div class="outline-text-4" id="text-1-4-8">
<ul class="org-ul">
<li><a href="./multi-task-class-CNAP.pdf">Paper</a></li>
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballsa+b(11-15-50)-11-16-05-15704-fast_and_flexib.pdf">Slides</a></li>
<li>Showed added classes and added test images without re-training</li>
<li>Meta-Dataset: a dataset of datasets</li>
<li><a href="https://github.com/cambridge-mlg/cnaps">Code</a></li>
</ul>
</div>
</div>
<div id="outline-container-org734423a" class="outline-4">
<h4 id="org734423a"><span class="section-number-4">1.4.9</span> Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation</h4>
<div class="outline-text-4" id="text-1-4-9">
<ul class="org-ul">
<li><a href="https://vuoristo.github.io/MMAML/mmaml_slides.pdf">Slides</a></li>
</ul>
</div>
</div>
<div id="outline-container-org650b5f3" class="outline-4">
<h4 id="org650b5f3"><span class="section-number-4">1.4.10</span> Efficient Meta Learning via Minibatch Proximal Update</h4>
<div class="outline-text-4" id="text-1-4-10">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westballa+b(11-15-50)-11-16-15-15706-efficient_meta_.pdf">Slides</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf8d2b6e" class="outline-4">
<h4 id="orgf8d2b6e"><span class="section-number-4">1.4.11</span> Reconciling meta-learning and continual learning with online mixtures of tasks</h4>
<div class="outline-text-4" id="text-1-4-11">
<ul class="org-ul">
<li><a href="https://drive.google.com/file/d/1nFyU_7YF01VXjxLHdQ3_EYkLhUV8Jhmy/view">Slides</a></li>
</ul>
</div>
</div>
<div id="outline-container-org1861b5b" class="outline-4">
<h4 id="org1861b5b"><span class="section-number-4">1.4.12</span> Beyond Online Balanced Descent: An Optimal Algorithmfor Smoothed Online Convex Optimization</h4>
<div class="outline-text-4" id="text-1-4-12">
<ul class="org-ul">
<li><a href="https://neurips.cc/media/Slides/nips/2019/westexhibitionhallb(11-15-50)-11-16-40-15821-beyond_online_b.pdf">slides</a></li>
<li><a href="./Online-balanced-descent.pdf">paper</a></li>
<li>Goal wasnt to minimize regret, was to acheive optimal competative ratio.</li>
<li>Competitive ratio: Minimize cost of learner action compared to best possible course of action</li>
</ul>
</div>
</div>
<div id="outline-container-org181aefb" class="outline-4">
<h4 id="org181aefb"><span class="section-number-4">1.4.13</span> Strategizing against No-regret Learners</h4>
<div class="outline-text-4" id="text-1-4-13">
<ul class="org-ul">
<li>Two types of agents: Strategic and Learning</li>
<li>Strategic agents maximize utility whereas learning agents play to learn how to play</li>
<li>Bidders behavior in online auctions is laregly consistent with a no-regret learner</li>
<li>mean-based algorithm: play the historically best action</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Sam Partee</p>
<p class="date">Created: 2019-12-11 Wed 17:51</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
